{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install lifelines --quiet\n",
        "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
        "from lifelines.statistics import proportional_hazard_test\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "0oJH7wMGWsfj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== User settings ==========\n",
        "DATA_PATH = \"data/churn_dataset.csv\"     # input dataset\n",
        "DURATION_COL = \"tenure\"\n",
        "EVENT_COL = \"churned\"\n",
        "KM_TIMES = [3, 6, 12, 24]     # months to report KM probabilities\n",
        "CORR_THRESHOLD = 0.70\n",
        "VIF_THRESHOLD = 5.0\n",
        "PENALIZER = 0.1               # L2 penalization for Cox to stabilize coefficients\n",
        "OUT_DIR = \"deliverables\"\n",
        "FIG_DIR = os.path.join(OUT_DIR, \"figures\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "m6z1lrIuilJs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Utilities ==========\n",
        "def save_text(path, text):\n",
        "    with open(path, \"w\") as f:\n",
        "        f.write(text)\n"
      ],
      "metadata": {
        "id": "0ZBXDtGmisNk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 1. Load data ==========\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "# Ensure required cols\n",
        "if DURATION_COL not in df.columns or EVENT_COL not in df.columns:\n",
        "    raise ValueError(f\"Dataset must contain '{DURATION_COL}' and '{EVENT_COL}' columns.\")"
      ],
      "metadata": {
        "id": "NGWt8QZrixmS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 2. Basic EDA and write eda_summary.txt ==========\n",
        "def eda_summary(df):\n",
        "    n = len(df)\n",
        "    missing = df.isnull().sum()\n",
        "    churn_rate = df[EVENT_COL].mean()\n",
        "    tenure_median = df[DURATION_COL].median()\n",
        "    tenure_mean = df[DURATION_COL].mean()\n",
        "    # Basic numerical stats sample\n",
        "    num_stats = df.select_dtypes(include=[np.number]).describe().T\n",
        "    # Frequency for categorical\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    eda_lines = []\n",
        "    eda_lines.append(\"Exploratory Data Analysis (EDA) — Summary\\n\")\n",
        "    eda_lines.append(f\"Total records: {n}\")\n",
        "    eda_lines.append(\"Missing values (per column):\")\n",
        "    for c, m in missing.items():\n",
        "        eda_lines.append(f\" - {c}: {m} ({(m/n):.1%})\")\n",
        "    eda_lines.append(f\"\\nChurn rate (event proportion): {churn_rate:.3f} ({churn_rate*100:.1f}%)\")\n",
        "    eda_lines.append(f\"Median tenure: {tenure_median} months; Mean tenure: {tenure_mean:.2f} months\\n\")\n",
        "    eda_lines.append(\"Numeric summary (selected):\")\n",
        "    eda_lines.append(num_stats[['count','mean','std','50%','min','max']].to_string())\n",
        "    if cat_cols:\n",
        "        eda_lines.append(\"\\nCategorical columns value counts (top 5):\")\n",
        "        for c in cat_cols:\n",
        "            eda_lines.append(f\" - {c}:\\n{df[c].value_counts(dropna=False).head().to_string()}\\n\")\n",
        "    return \"\\n\".join(eda_lines)\n",
        "\n",
        "eda_text = eda_summary(df)\n",
        "save_text(os.path.join(OUT_DIR, \"eda_summary.txt\"), eda_text)\n",
        "print(\"EDA written to eda_summary.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2vAqEP6i5SJ",
        "outputId": "c40f125d-0dca-4919-9248-fdb93d24d94e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EDA written to eda_summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 3. Kaplan-Meier (overall and by group) + write KM estimates ==========\n",
        "kmf = KaplanMeierFitter()\n",
        "T = df[DURATION_COL]\n",
        "E = df[EVENT_COL]\n",
        "kmf.fit(T, event_observed=E, label=\"All customers\")\n",
        "\n",
        "# Plot overall KM\n",
        "plt.figure(figsize=(8,5))\n",
        "kmf.plot_survival_function()\n",
        "plt.title(\"Kaplan-Meier Survival Function (Overall)\")\n",
        "plt.xlabel(\"Time (months)\")\n",
        "plt.ylabel(\"Survival Probability\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"km_overall.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Save KM numeric estimates at specified times\n",
        "km_lines = [\"Kaplan-Meier estimates (text)\"]\n",
        "for t in KM_TIMES:\n",
        "    prob = float(kmf.predict(t))\n",
        "    km_lines.append(f\"S({t} months) = {prob:.4f}\")\n",
        "# Try grouping by a meaningful column if present (e.g., 'usage_segment', 'segment', 'gender')\n",
        "group_col = None\n",
        "for candidate in [\"usage_segment\", \"segment\", \"gender\", \"plan\", \"contract\"]:\n",
        "    if candidate in df.columns:\n",
        "        group_col = candidate\n",
        "        break\n",
        "if group_col:\n",
        "    km_lines.append(f\"\\nBy group: {group_col}\")\n",
        "    plt.figure(figsize=(8,6))\n",
        "    for g in sorted(df[group_col].dropna().unique()):\n",
        "        ix = df[group_col] == g\n",
        "        kmf.fit(T[ix], E[ix], label=str(g))\n",
        "        probs = [float(kmf.predict(t)) for t in KM_TIMES]\n",
        "        km_lines.append(f\" - {g}: \" + \", \".join([f\"S({t})={p:.4f}\" for t,p in zip(KM_TIMES, probs)]))\n",
        "        kmf.plot_survival_function()\n",
        "    plt.title(f\"Kaplan-Meier by {group_col}\")\n",
        "    plt.xlabel(\"Time (months)\")\n",
        "    plt.ylabel(\"Survival Probability\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIG_DIR, f\"km_by_{group_col}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "save_text(os.path.join(OUT_DIR, \"km_estimates.txt\"), \"\\n\".join(km_lines))\n",
        "print(\"KM estimates written to km_estimates.txt and figures saved to figures/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKf9LCcdi6vl",
        "outputId": "a6539e77-2c9a-483d-e2d8-c7a5bc167e68"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KM estimates written to km_estimates.txt and figures saved to figures/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8MmQOJQWRRv",
        "outputId": "c2fb0417-5b2c-41e5-e483-69077d6daf91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature selection saved to feature_selection.txt\n"
          ]
        }
      ],
      "source": [
        "# ========== 4. Correlation and VIF-based feature selection ==========\n",
        "# Select numeric candidate features (exclude duration & event)\n",
        "numeric = df.select_dtypes(include=[np.number]).copy()\n",
        "numeric = numeric.drop(columns=[DURATION_COL, EVENT_COL], errors='ignore')\n",
        "num_cols = numeric.columns.tolist()\n",
        "\n",
        "corr_matrix = numeric.corr().abs()\n",
        "# find pairs with high correlation\n",
        "high_pairs = []\n",
        "for i in range(len(num_cols)):\n",
        "    for j in range(i+1, len(num_cols)):\n",
        "        a = num_cols[i]; b = num_cols[j]\n",
        "        r = corr_matrix.loc[a,b]\n",
        "        if r >= CORR_THRESHOLD:\n",
        "            high_pairs.append((a,b,r))\n",
        "# VIF computation: we need no missing values\n",
        "vif_df = pd.DataFrame(columns=['feature','VIF'])\n",
        "if len(num_cols) >= 2:\n",
        "    X = numeric.dropna().values\n",
        "    # compute VIF using numeric.dropna() and numeric.columns\n",
        "    Xv = numeric.dropna()\n",
        "    vif_list = []\n",
        "    for i in range(Xv.shape[1]):\n",
        "        try:\n",
        "            vif_val = variance_inflation_factor(Xv.values, i)\n",
        "        except Exception:\n",
        "            vif_val = np.nan\n",
        "        vif_list.append((Xv.columns[i], vif_val))\n",
        "    vif_df = pd.DataFrame(vif_list, columns=['feature','VIF']).sort_values('VIF', ascending=False)\n",
        "\n",
        "# Heuristic removal: for each high-correlation pair drop the one with higher mean correlation to others\n",
        "to_remove = set()\n",
        "for a,b,r in high_pairs:\n",
        "    mean_a = corr_matrix[a].mean()\n",
        "    mean_b = corr_matrix[b].mean()\n",
        "    drop = a if mean_a > mean_b else b\n",
        "    to_remove.add(drop)\n",
        "\n",
        "# Remove features with VIF > threshold\n",
        "for _, row in vif_df.iterrows():\n",
        "    if row['VIF'] > VIF_THRESHOLD:\n",
        "        to_remove.add(row['feature'])\n",
        "\n",
        "selected_numeric = [c for c in num_cols if c not in to_remove]\n",
        "\n",
        "# We'll encode categorical variables (one-hot) but only keep columns that are not perfectly multicollinear\n",
        "categorical = df.select_dtypes(include=['object','category']).columns.tolist()\n",
        "# Simple imputation for missing numeric and categorical for model fitting\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Impute numeric for VIF-selected columns\n",
        "if selected_numeric:\n",
        "    numeric_imputed = pd.DataFrame(imputer_num.fit_transform(df[selected_numeric]), columns=selected_numeric)\n",
        "else:\n",
        "    numeric_imputed = pd.DataFrame(index=df.index)\n",
        "\n",
        "# One-hot encode categoricals\n",
        "encoded_df = pd.DataFrame(index=df.index)\n",
        "if categorical:\n",
        "    # Fill missing\n",
        "    cat_df = df[categorical].fillna('MISSING').astype(str)\n",
        "    ohe = OneHotEncoder(drop='first', sparse_output=False)\n",
        "    ohe_arr = ohe.fit_transform(cat_df)\n",
        "    ohe_cols = ohe.get_feature_names_out(categorical)\n",
        "    encoded_df = pd.DataFrame(ohe_arr, columns=ohe_cols, index=df.index)\n",
        "\n",
        "# Final feature list\n",
        "final_features = list(numeric_imputed.columns) + list(encoded_df.columns)\n",
        "if not final_features:\n",
        "    raise ValueError(\"No features available for Cox model after selection. Check your dataset and thresholds.\")\n",
        "\n",
        "# Combine into model df\n",
        "model_df = pd.concat([df[[DURATION_COL, EVENT_COL]].reset_index(drop=True),\n",
        "                      numeric_imputed.reset_index(drop=True),\n",
        "                      encoded_df.reset_index(drop=True)], axis=1).dropna()\n",
        "\n",
        "# Save selection summary\n",
        "sel_lines = [\"Feature selection summary\"]\n",
        "sel_lines.append(f\"Initial numeric cols: {num_cols}\")\n",
        "sel_lines.append(f\"High-correlation pairs (r>={CORR_THRESHOLD}): {high_pairs}\")\n",
        "sel_lines.append(\"Removed (heuristic + VIF): \" + str(sorted(list(to_remove))))\n",
        "sel_lines.append(\"Selected numeric features: \" + str(selected_numeric))\n",
        "sel_lines.append(\"Categorical encoded columns included: \" + str(list(encoded_df.columns)))\n",
        "save_text(os.path.join(OUT_DIR, \"feature_selection.txt\"), \"\\n\".join(sel_lines))\n",
        "print(\"Feature selection saved to feature_selection.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 5. Fit penalized Cox proportional hazards model ==========\n",
        "cph = CoxPHFitter(penalizer=PENALIZER)\n",
        "cph.fit(model_df, duration_col=DURATION_COL, event_col=EVENT_COL)\n",
        "# Save the summary (table)\n",
        "save_text(os.path.join(OUT_DIR, \"cox_summary.txt\"), cph.summary.to_string())\n",
        "print(\"Cox model summary saved to cox_summary.txt\")\n",
        "\n",
        "# Save a coefficient plot\n",
        "plt.figure(figsize=(8,6))\n",
        "cph.plot()\n",
        "plt.title(\"Cox coefficients\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"cox_coefficients.png\"))\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wpk8yOfjaD4",
        "outputId": "6c420935-85ba-4245-cbd1-6054184162be"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cox model summary saved to cox_summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 6. PH assumption test (Schoenfeld residuals) ==========\n",
        "ph_test = proportional_hazard_test(cph, model_df, time_transform='rank')\n",
        "# Compose interpretation text\n",
        "def compose_cox_interpretation(cph, ph_test):\n",
        "    lines = []\n",
        "    lines.append(\"Cox Proportional Hazards Model — Written Interpretation\\n\")\n",
        "    lines.append(\"Variables and hazard ratios (exp(coef)):\")\n",
        "    for idx, row in cph.summary.iterrows():\n",
        "        hr = np.exp(row['coef'])\n",
        "        lower = np.exp(row['coef lower 95%'])\n",
        "        upper = np.exp(row['coef upper 95%'])\n",
        "        p = row['p']\n",
        "        lines.append(f\" - {idx}: HR = {hr:.3f}, 95% CI = ({lower:.3f}, {upper:.3f}), p = {p:.4f}\")\n",
        "        if p < 0.05:\n",
        "            if hr > 1:\n",
        "                lines.append(f\"    Interpretation: {idx} is significantly associated with increased hazard (faster churn).\")\n",
        "            else:\n",
        "                lines.append(f\"    Interpretation: {idx} is significantly associated with decreased hazard (slower churn).\")\n",
        "        else:\n",
        "            lines.append(f\"    Interpretation: {idx} is not statistically significant at alpha=0.05.\")\n",
        "\n",
        "    lines.append(\"\\nProportional Hazards test (Schoenfeld residuals - per covariate):\")\n",
        "    ph_violation = False\n",
        "    per_df = ph_test.summary\n",
        "    if not per_df.empty:\n",
        "        lines.append(\"\\nPer-variable PH test p-values:\")\n",
        "        for cov, row in per_df.iterrows():\n",
        "            lines.append(f\" - {cov}: p = {row['p']:.4f}\")\n",
        "            if row['p'] <= 0.05: # Using alpha = 0.05 as a threshold\n",
        "                ph_violation = True\n",
        "    else:\n",
        "        lines.append(\" - No covariates found for PH test.\")\n",
        "\n",
        "    lines.append(\"\\nOverall Proportional Hazards Assumption Conclusion:\")\n",
        "    if ph_violation:\n",
        "        lines.append(\" - Conclusion: Evidence of PH violation for at least one covariate (p <= 0.05). Consider time interactions or stratification for the violating covariates.\")\n",
        "    else:\n",
        "        lines.append(\" - Conclusion: No evidence of PH violation for any covariate (all p > 0.05).\")\n",
        "\n",
        "    lines.append(f\"\\nConcordance index (C-index): {cph.concordance_index_:.3f}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "cox_interp_text = compose_cox_interpretation(cph, ph_test)\n",
        "save_text(os.path.join(OUT_DIR, \"cox_interpretation.txt\"), cox_interp_text)\n",
        "print(\"Cox interpretation written to cox_interpretation.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff2erm_ejncM",
        "outputId": "cc42a5f4-599a-4aaf-a844-ecb6e7a333f3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cox interpretation written to cox_interpretation.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 7. Predictions: risk score and survival at e.g., 6,12 months ==========\n",
        "# Predict partial hazard (risk score)\n",
        "pred_df = model_df.copy()\n",
        "pred_df['risk_score'] = cph.predict_partial_hazard(pred_df)\n",
        "# Predict survival function for first 48 months and extract numeric survival at specific times\n",
        "surv_funcs = cph.predict_survival_function(pred_df, times=np.arange(0, 61))  # 0..60 months\n",
        "# Extract survival at KM_TIMES and append average per customer\n",
        "for t in KM_TIMES:\n",
        "    pred_df[f\"survival_{t}m\"] = surv_funcs.loc[t].values\n",
        "# Save predictions\n",
        "pred_df.to_csv(os.path.join(OUT_DIR, \"predictions.csv\"), index=False)\n",
        "print(\"Predictions saved to predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBnaL3xkjxdX",
        "outputId": "a32efaef-a496-496c-9bcd-2a8daa2903b4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 8. Save key figures and list deliverables ==========\n",
        "deliverables_list = [\n",
        "    \"eda_summary.txt\",\n",
        "    \"km_estimates.txt\",\n",
        "    \"feature_selection.txt\",\n",
        "    \"cox_summary.txt\",\n",
        "    \"cox_interpretation.txt\",\n",
        "    \"predictions.csv\",\n",
        "    \"figures/ (km_overall.png, km_by_group.png if group present, cox_coefficients.png)\",\n",
        "]\n",
        "save_text(os.path.join(OUT_DIR, \"deliverables_list.txt\"), \"\\n\".join(deliverables_list))\n",
        "print(\"All deliverables saved under folder:\", OUT_DIR)\n",
        "\n",
        "# End of script"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIgkP6XSj25n",
        "outputId": "3784a5a4-8892-438e-d100-2f91b64e4d2e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All deliverables saved under folder: deliverables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install lifelines --quiet\n",
        "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
        "from lifelines.statistics import proportional_hazard_test\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "pCkigtdbfFpn"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  1. Create Folder Structure\n",
        "# ============================================================\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"outputs\", exist_ok=True)"
      ],
      "metadata": {
        "id": "rxsmFVm8fQvL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  2. Generate Dataset (Simulated Realistic Telco Churn Data)\n",
        "# ============================================================\n",
        "np.random.seed(42)\n",
        "n = 500\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"tenure\": np.random.exponential(scale=365, size=n).astype(int),\n",
        "    \"churned\": np.random.binomial(1, 0.35, n),\n",
        "    \"age\": np.random.randint(18, 70, n),\n",
        "    \"monthly_charges\": np.random.uniform(20, 120, n),\n",
        "    \"contract_type\": np.random.choice([\"Month-to-month\", \"One year\", \"Two year\"], n),\n",
        "    \"gender\": np.random.choice([\"Male\", \"Female\"], n),\n",
        "    \"payment_method\": np.random.choice([\"Card\", \"UPI\", \"Bank Transfer\"], n)\n",
        "})\n",
        "df.to_csv(\"data/churn_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "mU6dLifhfhcb"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  3. EDA SUMMARY\n",
        "# ============================================================\n",
        "eda_text = []\n",
        "eda_text.append(\"### EDA SUMMARY\\n\")\n",
        "eda_text.append(f\"Total Records: {len(df)}\")\n",
        "eda_text.append(f\"Churn Rate: {df['churned'].mean():.2f}\")\n",
        "eda_text.append(f\"Average Tenure: {df['tenure'].mean():.2f}\")\n",
        "eda_text.append(\"\\nContract Type Distribution:\\n\")\n",
        "eda_text.append(str(df['contract_type'].value_counts()))\n",
        "eda_text.append(\"\\n\\nMonthly Charges Summary:\\n\")\n",
        "eda_text.append(str(df['monthly_charges'].describe()))\n",
        "\n",
        "with open(\"outputs/eda_summary.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(eda_text))"
      ],
      "metadata": {
        "id": "Y30B6YCHf5Sy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  4. Kaplan-Meier Estimator\n",
        "# ============================================================\n",
        "km = KaplanMeierFitter()\n",
        "km.fit(durations=df[\"tenure\"], event_observed=df[\"churned\"])\n",
        "\n",
        "km_text = []\n",
        "km_text.append(\"### Kaplan-Meier Survival Output (First 20 Rows)\\n\")\n",
        "km_text.append(str(km.survival_function_.head(20)))\n",
        "\n",
        "with open(\"outputs/km_output.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(km_text))\n",
        "\n",
        "# Plot KM Curve\n",
        "km.plot_survival_function()\n",
        "plt.title(\"Kaplan-Meier Survival Curve\")\n",
        "plt.xlabel(\"Time (Days)\")\n",
        "plt.ylabel(\"Survival Probability\")\n",
        "plt.savefig(\"outputs/km_plot.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "mXhjvybBf5GI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  5. COX PROPORTIONAL HAZARDS MODEL\n",
        "# ============================================================\n",
        "# Encode categorical variables\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "cph = CoxPHFitter()\n",
        "cph.fit(df_encoded, duration_col=\"tenure\", event_col=\"churned\")\n",
        "\n",
        "# Save summary\n",
        "cph.summary.to_csv(\"outputs/cox_summary.csv\")\n",
        "\n",
        "# Interpretation Text\n",
        "cox_text = []\n",
        "cox_text.append(\"### Cox Proportional Hazards Model Interpretation\\n\")\n",
        "\n",
        "for index, row in cph.summary.iterrows():\n",
        "    hr = row[\"exp(coef)\"]\n",
        "    p = row[\"p\"]\n",
        "    effect = \"significant\" if p < 0.05 else \"not significant\"\n",
        "\n",
        "    cox_text.append(f\"{index}: HR={hr:.3f}, p={p:.4f} → {effect}\")\n",
        "\n",
        "with open(\"outputs/cox_interpretation.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(cox_text))"
      ],
      "metadata": {
        "id": "QNVLVNhaf45t"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  6. PROPORTIONAL HAZARD ASSUMPTION TEST\n",
        "# ============================================================\n",
        "ph_results = proportional_hazard_test(cph, df_encoded, time_transform='rank')\n",
        "\n",
        "ph_text = []\n",
        "ph_text.append(\"### Schoenfeld Residual Test Results (PH Assumption)\\n\")\n",
        "ph_text.append(str(ph_results.summary))\n",
        "\n",
        "with open(\"outputs/ph_assumption_report.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(ph_text))\n",
        "\n"
      ],
      "metadata": {
        "id": "_pv0_W6gf4pV"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#============================================================\n",
        "#  DONE\n",
        "# ============================================================\n",
        "print(\"All tasks completed successfully.\")\n",
        "print(\"Check the 'outputs' folder for all required deliverables.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkjszHyDhJD_",
        "outputId": "7a466947-d331-4323-cb66-99a50d0380b8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tasks completed successfully.\n",
            "Check the 'outputs' folder for all required deliverables.\n"
          ]
        }
      ]
    }
  ]
}